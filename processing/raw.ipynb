{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reads the data from the raw directories `internal_data` and saves all the found frames in a big `raw.csv` file with keypoint annotations. It rounds the keypoint locations to 2 decimal places and removes duplicates by checking for `factor == dup_num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_directory_path' with the path to your dataset\n",
    "data_root = \"E:\\internal_data\"\n",
    "\n",
    "include_xyz = False\n",
    "\n",
    "with open(\"./point_ids.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    POINT_IDS = data[\"point_ids\"]\n",
    "\n",
    "\n",
    "def get_folders(root):\n",
    "    return [f for f in os.listdir(root) if os.path.isdir(os.path.join(root, f))]\n",
    "\n",
    "\n",
    "def get_files(root):\n",
    "    return [f for f in os.listdir(root) if os.path.isfile(os.path.join(root, f))]\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    frames = []\n",
    "    for frame in data:\n",
    "        r = process_frame(frame)\n",
    "        if r is None:\n",
    "            continue\n",
    "        frame_num, img_path, xy, xyz = r\n",
    "        frames.append((frame_num, img_path, xy, xyz))\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def process_frame(data):\n",
    "    point_ids = data[\"point_ids\"]\n",
    "    if point_ids != POINT_IDS:\n",
    "        print(\"Point IDs do not match\")\n",
    "        return\n",
    "\n",
    "    frame_num = data[\"frame_num\"]\n",
    "    img_path = data[\"path\"]\n",
    "    factor = data[\"factor\"]\n",
    "    dup_num = data[\"dup_num\"]\n",
    "    xy = data[\"xy\"]\n",
    "    xyz = data[\"xyz\"]\n",
    "\n",
    "    if int(factor) != int(dup_num):\n",
    "        return None\n",
    "\n",
    "    xy = np.array(xy).astype(np.float32)\n",
    "    xyz = np.array(xyz).astype(np.float32)\n",
    "\n",
    "    xy = np.round(xy, 2)\n",
    "    xyz = np.round(xyz, 2)\n",
    "\n",
    "    return frame_num, img_path, xy, xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 627/627 [03:47<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "camera_folders = get_folders(data_root)\n",
    "FILES = []\n",
    "\n",
    "for camera_folder in camera_folders:\n",
    "    C = camera_folder.replace(\"C\", \"\")\n",
    "    subjects = get_folders(os.path.join(data_root, camera_folder))\n",
    "\n",
    "    for subject in subjects:\n",
    "        S = subject.replace(\"S\", \"\")\n",
    "        sequences = get_files(os.path.join(data_root, camera_folder, subject))\n",
    "\n",
    "        for sequence in sequences:\n",
    "            if not sequence.endswith(\".json\"):\n",
    "                continue\n",
    "            seq = sequence.replace(\".json\", \"\")\n",
    "            A = seq[seq.index(\"A\") + 1 : seq.index(\"D\")]\n",
    "            D = seq[seq.index(\"D\") + 1 : len(seq)]\n",
    "\n",
    "            file = os.path.join(data_root, camera_folder, subject, sequence)\n",
    "            FILES.append((C, S, A, D, file))\n",
    "\n",
    "with open(\"../data/raw.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    columns = [\"C\", \"S\", \"A\", \"D\", \"frame_num\", \"img_path\"]\n",
    "\n",
    "    for point_id in POINT_IDS:\n",
    "        columns.append(f\"{point_id}_u\")\n",
    "        columns.append(f\"{point_id}_v\")\n",
    "\n",
    "    if include_xyz:\n",
    "        for point_id in POINT_IDS:\n",
    "            columns.append(f\"{point_id}_x\")\n",
    "            columns.append(f\"{point_id}_y\")\n",
    "            columns.append(f\"{point_id}_z\")\n",
    "\n",
    "    writer.writerow(columns)\n",
    "\n",
    "    for C, S, A, D, file in tqdm.tqdm(FILES):\n",
    "        frames = process_file(file)\n",
    "\n",
    "        for frame in frames:\n",
    "            frame_num, img_path, xy, xyz = frame\n",
    "            columns = [C, S, A, D, frame_num, img_path]\n",
    "            for i in range(len(POINT_IDS)):\n",
    "                columns.append(xy[i][0])\n",
    "                columns.append(xy[i][1])\n",
    "            if include_xyz:\n",
    "                for i in range(len(POINT_IDS)):\n",
    "                    columns.append(xyz[i][0])\n",
    "                    columns.append(xyz[i][1])\n",
    "                    columns.append(xyz[i][2])\n",
    "            writer.writerow(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 531287\n",
      "All unique\n"
     ]
    }
   ],
   "source": [
    "df_processed = pd.read_csv('../data/raw.csv')\n",
    "uniques_img_path = df_processed['img_path'].unique()\n",
    "print(f\"Number of frames: {len(df_processed)}\")\n",
    "if len(uniques_img_path) == len(df_processed):\n",
    "    print(\"All unique\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
