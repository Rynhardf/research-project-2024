{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_model, load_config, get_keypoints, draw_keypoints\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('./configs/config_YOLO_x.yaml')\n",
    "model = load_model(config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 640, 640])\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('./example_images/demo_cropped.jpg')\n",
    "image = cv2.resize(image, config['dataset']['preprocess']['input_size'])\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = image.astype('float32')\n",
    "image /= 255.0\n",
    "\n",
    "image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(image)\n",
    "keypoints1 = get_keypoints(out, config)[0]\n",
    "model.train()\n",
    "out = model(image)\n",
    "keypoints2 = get_keypoints(out, config)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show = cv2.imread('./example_images/demo_cropped.jpg')\n",
    "image_show = cv2.resize(image_show, config['dataset']['preprocess']['input_size'])\n",
    "\n",
    "# image_show1 = draw_keypoints(image_show, keypoints1, np.ones(len(keypoints1)))\n",
    "image_show2 = draw_keypoints(image_show.copy(), keypoints2, np.ones(len(keypoints2)))\n",
    "\n",
    "# cv2.imshow('keypoints1', image_show1)\n",
    "cv2.imshow('keypoints2', image_show2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load('./weights/yolov8x-pose.pt')\n",
    "model = loaded_model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.DoubleTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m rand_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[1;32m----> 3\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrand_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:102\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:141\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 141\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    142\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rynha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.DoubleTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "rand_input = torch.rand(1, 3, 512, 512)\n",
    "out = model(rand_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['model.0.conv.weight', 'model.0.bn.weight', 'model.0.bn.bias', 'model.0.bn.running_mean', 'model.0.bn.running_var', 'model.0.bn.num_batches_tracked', 'model.1.conv.weight', 'model.1.bn.weight', 'model.1.bn.bias', 'model.1.bn.running_mean', 'model.1.bn.running_var', 'model.1.bn.num_batches_tracked', 'model.2.cv1.conv.weight', 'model.2.cv1.bn.weight', 'model.2.cv1.bn.bias', 'model.2.cv1.bn.running_mean', 'model.2.cv1.bn.running_var', 'model.2.cv1.bn.num_batches_tracked', 'model.2.cv2.conv.weight', 'model.2.cv2.bn.weight', 'model.2.cv2.bn.bias', 'model.2.cv2.bn.running_mean', 'model.2.cv2.bn.running_var', 'model.2.cv2.bn.num_batches_tracked', 'model.2.m.0.cv1.conv.weight', 'model.2.m.0.cv1.bn.weight', 'model.2.m.0.cv1.bn.bias', 'model.2.m.0.cv1.bn.running_mean', 'model.2.m.0.cv1.bn.running_var', 'model.2.m.0.cv1.bn.num_batches_tracked', 'model.2.m.0.cv2.conv.weight', 'model.2.m.0.cv2.bn.weight', 'model.2.m.0.cv2.bn.bias', 'model.2.m.0.cv2.bn.running_mean', 'model.2.m.0.cv2.bn.running_var', 'model.2.m.0.cv2.bn.num_batches_tracked', 'model.2.m.1.cv1.conv.weight', 'model.2.m.1.cv1.bn.weight', 'model.2.m.1.cv1.bn.bias', 'model.2.m.1.cv1.bn.running_mean', 'model.2.m.1.cv1.bn.running_var', 'model.2.m.1.cv1.bn.num_batches_tracked', 'model.2.m.1.cv2.conv.weight', 'model.2.m.1.cv2.bn.weight', 'model.2.m.1.cv2.bn.bias', 'model.2.m.1.cv2.bn.running_mean', 'model.2.m.1.cv2.bn.running_var', 'model.2.m.1.cv2.bn.num_batches_tracked', 'model.2.m.2.cv1.conv.weight', 'model.2.m.2.cv1.bn.weight', 'model.2.m.2.cv1.bn.bias', 'model.2.m.2.cv1.bn.running_mean', 'model.2.m.2.cv1.bn.running_var', 'model.2.m.2.cv1.bn.num_batches_tracked', 'model.2.m.2.cv2.conv.weight', 'model.2.m.2.cv2.bn.weight', 'model.2.m.2.cv2.bn.bias', 'model.2.m.2.cv2.bn.running_mean', 'model.2.m.2.cv2.bn.running_var', 'model.2.m.2.cv2.bn.num_batches_tracked', 'model.3.conv.weight', 'model.3.bn.weight', 'model.3.bn.bias', 'model.3.bn.running_mean', 'model.3.bn.running_var', 'model.3.bn.num_batches_tracked', 'model.4.cv1.conv.weight', 'model.4.cv1.bn.weight', 'model.4.cv1.bn.bias', 'model.4.cv1.bn.running_mean', 'model.4.cv1.bn.running_var', 'model.4.cv1.bn.num_batches_tracked', 'model.4.cv2.conv.weight', 'model.4.cv2.bn.weight', 'model.4.cv2.bn.bias', 'model.4.cv2.bn.running_mean', 'model.4.cv2.bn.running_var', 'model.4.cv2.bn.num_batches_tracked', 'model.4.m.0.cv1.conv.weight', 'model.4.m.0.cv1.bn.weight', 'model.4.m.0.cv1.bn.bias', 'model.4.m.0.cv1.bn.running_mean', 'model.4.m.0.cv1.bn.running_var', 'model.4.m.0.cv1.bn.num_batches_tracked', 'model.4.m.0.cv2.conv.weight', 'model.4.m.0.cv2.bn.weight', 'model.4.m.0.cv2.bn.bias', 'model.4.m.0.cv2.bn.running_mean', 'model.4.m.0.cv2.bn.running_var', 'model.4.m.0.cv2.bn.num_batches_tracked', 'model.4.m.1.cv1.conv.weight', 'model.4.m.1.cv1.bn.weight', 'model.4.m.1.cv1.bn.bias', 'model.4.m.1.cv1.bn.running_mean', 'model.4.m.1.cv1.bn.running_var', 'model.4.m.1.cv1.bn.num_batches_tracked', 'model.4.m.1.cv2.conv.weight', 'model.4.m.1.cv2.bn.weight', 'model.4.m.1.cv2.bn.bias', 'model.4.m.1.cv2.bn.running_mean', 'model.4.m.1.cv2.bn.running_var', 'model.4.m.1.cv2.bn.num_batches_tracked', 'model.4.m.2.cv1.conv.weight', 'model.4.m.2.cv1.bn.weight', 'model.4.m.2.cv1.bn.bias', 'model.4.m.2.cv1.bn.running_mean', 'model.4.m.2.cv1.bn.running_var', 'model.4.m.2.cv1.bn.num_batches_tracked', 'model.4.m.2.cv2.conv.weight', 'model.4.m.2.cv2.bn.weight', 'model.4.m.2.cv2.bn.bias', 'model.4.m.2.cv2.bn.running_mean', 'model.4.m.2.cv2.bn.running_var', 'model.4.m.2.cv2.bn.num_batches_tracked', 'model.4.m.3.cv1.conv.weight', 'model.4.m.3.cv1.bn.weight', 'model.4.m.3.cv1.bn.bias', 'model.4.m.3.cv1.bn.running_mean', 'model.4.m.3.cv1.bn.running_var', 'model.4.m.3.cv1.bn.num_batches_tracked', 'model.4.m.3.cv2.conv.weight', 'model.4.m.3.cv2.bn.weight', 'model.4.m.3.cv2.bn.bias', 'model.4.m.3.cv2.bn.running_mean', 'model.4.m.3.cv2.bn.running_var', 'model.4.m.3.cv2.bn.num_batches_tracked', 'model.4.m.4.cv1.conv.weight', 'model.4.m.4.cv1.bn.weight', 'model.4.m.4.cv1.bn.bias', 'model.4.m.4.cv1.bn.running_mean', 'model.4.m.4.cv1.bn.running_var', 'model.4.m.4.cv1.bn.num_batches_tracked', 'model.4.m.4.cv2.conv.weight', 'model.4.m.4.cv2.bn.weight', 'model.4.m.4.cv2.bn.bias', 'model.4.m.4.cv2.bn.running_mean', 'model.4.m.4.cv2.bn.running_var', 'model.4.m.4.cv2.bn.num_batches_tracked', 'model.4.m.5.cv1.conv.weight', 'model.4.m.5.cv1.bn.weight', 'model.4.m.5.cv1.bn.bias', 'model.4.m.5.cv1.bn.running_mean', 'model.4.m.5.cv1.bn.running_var', 'model.4.m.5.cv1.bn.num_batches_tracked', 'model.4.m.5.cv2.conv.weight', 'model.4.m.5.cv2.bn.weight', 'model.4.m.5.cv2.bn.bias', 'model.4.m.5.cv2.bn.running_mean', 'model.4.m.5.cv2.bn.running_var', 'model.4.m.5.cv2.bn.num_batches_tracked', 'model.5.conv.weight', 'model.5.bn.weight', 'model.5.bn.bias', 'model.5.bn.running_mean', 'model.5.bn.running_var', 'model.5.bn.num_batches_tracked', 'model.6.cv1.conv.weight', 'model.6.cv1.bn.weight', 'model.6.cv1.bn.bias', 'model.6.cv1.bn.running_mean', 'model.6.cv1.bn.running_var', 'model.6.cv1.bn.num_batches_tracked', 'model.6.cv2.conv.weight', 'model.6.cv2.bn.weight', 'model.6.cv2.bn.bias', 'model.6.cv2.bn.running_mean', 'model.6.cv2.bn.running_var', 'model.6.cv2.bn.num_batches_tracked', 'model.6.m.0.cv1.conv.weight', 'model.6.m.0.cv1.bn.weight', 'model.6.m.0.cv1.bn.bias', 'model.6.m.0.cv1.bn.running_mean', 'model.6.m.0.cv1.bn.running_var', 'model.6.m.0.cv1.bn.num_batches_tracked', 'model.6.m.0.cv2.conv.weight', 'model.6.m.0.cv2.bn.weight', 'model.6.m.0.cv2.bn.bias', 'model.6.m.0.cv2.bn.running_mean', 'model.6.m.0.cv2.bn.running_var', 'model.6.m.0.cv2.bn.num_batches_tracked', 'model.6.m.1.cv1.conv.weight', 'model.6.m.1.cv1.bn.weight', 'model.6.m.1.cv1.bn.bias', 'model.6.m.1.cv1.bn.running_mean', 'model.6.m.1.cv1.bn.running_var', 'model.6.m.1.cv1.bn.num_batches_tracked', 'model.6.m.1.cv2.conv.weight', 'model.6.m.1.cv2.bn.weight', 'model.6.m.1.cv2.bn.bias', 'model.6.m.1.cv2.bn.running_mean', 'model.6.m.1.cv2.bn.running_var', 'model.6.m.1.cv2.bn.num_batches_tracked', 'model.6.m.2.cv1.conv.weight', 'model.6.m.2.cv1.bn.weight', 'model.6.m.2.cv1.bn.bias', 'model.6.m.2.cv1.bn.running_mean', 'model.6.m.2.cv1.bn.running_var', 'model.6.m.2.cv1.bn.num_batches_tracked', 'model.6.m.2.cv2.conv.weight', 'model.6.m.2.cv2.bn.weight', 'model.6.m.2.cv2.bn.bias', 'model.6.m.2.cv2.bn.running_mean', 'model.6.m.2.cv2.bn.running_var', 'model.6.m.2.cv2.bn.num_batches_tracked', 'model.6.m.3.cv1.conv.weight', 'model.6.m.3.cv1.bn.weight', 'model.6.m.3.cv1.bn.bias', 'model.6.m.3.cv1.bn.running_mean', 'model.6.m.3.cv1.bn.running_var', 'model.6.m.3.cv1.bn.num_batches_tracked', 'model.6.m.3.cv2.conv.weight', 'model.6.m.3.cv2.bn.weight', 'model.6.m.3.cv2.bn.bias', 'model.6.m.3.cv2.bn.running_mean', 'model.6.m.3.cv2.bn.running_var', 'model.6.m.3.cv2.bn.num_batches_tracked', 'model.6.m.4.cv1.conv.weight', 'model.6.m.4.cv1.bn.weight', 'model.6.m.4.cv1.bn.bias', 'model.6.m.4.cv1.bn.running_mean', 'model.6.m.4.cv1.bn.running_var', 'model.6.m.4.cv1.bn.num_batches_tracked', 'model.6.m.4.cv2.conv.weight', 'model.6.m.4.cv2.bn.weight', 'model.6.m.4.cv2.bn.bias', 'model.6.m.4.cv2.bn.running_mean', 'model.6.m.4.cv2.bn.running_var', 'model.6.m.4.cv2.bn.num_batches_tracked', 'model.6.m.5.cv1.conv.weight', 'model.6.m.5.cv1.bn.weight', 'model.6.m.5.cv1.bn.bias', 'model.6.m.5.cv1.bn.running_mean', 'model.6.m.5.cv1.bn.running_var', 'model.6.m.5.cv1.bn.num_batches_tracked', 'model.6.m.5.cv2.conv.weight', 'model.6.m.5.cv2.bn.weight', 'model.6.m.5.cv2.bn.bias', 'model.6.m.5.cv2.bn.running_mean', 'model.6.m.5.cv2.bn.running_var', 'model.6.m.5.cv2.bn.num_batches_tracked', 'model.7.conv.weight', 'model.7.bn.weight', 'model.7.bn.bias', 'model.7.bn.running_mean', 'model.7.bn.running_var', 'model.7.bn.num_batches_tracked', 'model.8.cv1.conv.weight', 'model.8.cv1.bn.weight', 'model.8.cv1.bn.bias', 'model.8.cv1.bn.running_mean', 'model.8.cv1.bn.running_var', 'model.8.cv1.bn.num_batches_tracked', 'model.8.cv2.conv.weight', 'model.8.cv2.bn.weight', 'model.8.cv2.bn.bias', 'model.8.cv2.bn.running_mean', 'model.8.cv2.bn.running_var', 'model.8.cv2.bn.num_batches_tracked', 'model.8.m.0.cv1.conv.weight', 'model.8.m.0.cv1.bn.weight', 'model.8.m.0.cv1.bn.bias', 'model.8.m.0.cv1.bn.running_mean', 'model.8.m.0.cv1.bn.running_var', 'model.8.m.0.cv1.bn.num_batches_tracked', 'model.8.m.0.cv2.conv.weight', 'model.8.m.0.cv2.bn.weight', 'model.8.m.0.cv2.bn.bias', 'model.8.m.0.cv2.bn.running_mean', 'model.8.m.0.cv2.bn.running_var', 'model.8.m.0.cv2.bn.num_batches_tracked', 'model.8.m.1.cv1.conv.weight', 'model.8.m.1.cv1.bn.weight', 'model.8.m.1.cv1.bn.bias', 'model.8.m.1.cv1.bn.running_mean', 'model.8.m.1.cv1.bn.running_var', 'model.8.m.1.cv1.bn.num_batches_tracked', 'model.8.m.1.cv2.conv.weight', 'model.8.m.1.cv2.bn.weight', 'model.8.m.1.cv2.bn.bias', 'model.8.m.1.cv2.bn.running_mean', 'model.8.m.1.cv2.bn.running_var', 'model.8.m.1.cv2.bn.num_batches_tracked', 'model.8.m.2.cv1.conv.weight', 'model.8.m.2.cv1.bn.weight', 'model.8.m.2.cv1.bn.bias', 'model.8.m.2.cv1.bn.running_mean', 'model.8.m.2.cv1.bn.running_var', 'model.8.m.2.cv1.bn.num_batches_tracked', 'model.8.m.2.cv2.conv.weight', 'model.8.m.2.cv2.bn.weight', 'model.8.m.2.cv2.bn.bias', 'model.8.m.2.cv2.bn.running_mean', 'model.8.m.2.cv2.bn.running_var', 'model.8.m.2.cv2.bn.num_batches_tracked', 'model.9.cv1.conv.weight', 'model.9.cv1.bn.weight', 'model.9.cv1.bn.bias', 'model.9.cv1.bn.running_mean', 'model.9.cv1.bn.running_var', 'model.9.cv1.bn.num_batches_tracked', 'model.9.cv2.conv.weight', 'model.9.cv2.bn.weight', 'model.9.cv2.bn.bias', 'model.9.cv2.bn.running_mean', 'model.9.cv2.bn.running_var', 'model.9.cv2.bn.num_batches_tracked', 'model.12.cv1.conv.weight', 'model.12.cv1.bn.weight', 'model.12.cv1.bn.bias', 'model.12.cv1.bn.running_mean', 'model.12.cv1.bn.running_var', 'model.12.cv1.bn.num_batches_tracked', 'model.12.cv2.conv.weight', 'model.12.cv2.bn.weight', 'model.12.cv2.bn.bias', 'model.12.cv2.bn.running_mean', 'model.12.cv2.bn.running_var', 'model.12.cv2.bn.num_batches_tracked', 'model.12.m.0.cv1.conv.weight', 'model.12.m.0.cv1.bn.weight', 'model.12.m.0.cv1.bn.bias', 'model.12.m.0.cv1.bn.running_mean', 'model.12.m.0.cv1.bn.running_var', 'model.12.m.0.cv1.bn.num_batches_tracked', 'model.12.m.0.cv2.conv.weight', 'model.12.m.0.cv2.bn.weight', 'model.12.m.0.cv2.bn.bias', 'model.12.m.0.cv2.bn.running_mean', 'model.12.m.0.cv2.bn.running_var', 'model.12.m.0.cv2.bn.num_batches_tracked', 'model.12.m.1.cv1.conv.weight', 'model.12.m.1.cv1.bn.weight', 'model.12.m.1.cv1.bn.bias', 'model.12.m.1.cv1.bn.running_mean', 'model.12.m.1.cv1.bn.running_var', 'model.12.m.1.cv1.bn.num_batches_tracked', 'model.12.m.1.cv2.conv.weight', 'model.12.m.1.cv2.bn.weight', 'model.12.m.1.cv2.bn.bias', 'model.12.m.1.cv2.bn.running_mean', 'model.12.m.1.cv2.bn.running_var', 'model.12.m.1.cv2.bn.num_batches_tracked', 'model.12.m.2.cv1.conv.weight', 'model.12.m.2.cv1.bn.weight', 'model.12.m.2.cv1.bn.bias', 'model.12.m.2.cv1.bn.running_mean', 'model.12.m.2.cv1.bn.running_var', 'model.12.m.2.cv1.bn.num_batches_tracked', 'model.12.m.2.cv2.conv.weight', 'model.12.m.2.cv2.bn.weight', 'model.12.m.2.cv2.bn.bias', 'model.12.m.2.cv2.bn.running_mean', 'model.12.m.2.cv2.bn.running_var', 'model.12.m.2.cv2.bn.num_batches_tracked', 'model.15.cv1.conv.weight', 'model.15.cv1.bn.weight', 'model.15.cv1.bn.bias', 'model.15.cv1.bn.running_mean', 'model.15.cv1.bn.running_var', 'model.15.cv1.bn.num_batches_tracked', 'model.15.cv2.conv.weight', 'model.15.cv2.bn.weight', 'model.15.cv2.bn.bias', 'model.15.cv2.bn.running_mean', 'model.15.cv2.bn.running_var', 'model.15.cv2.bn.num_batches_tracked', 'model.15.m.0.cv1.conv.weight', 'model.15.m.0.cv1.bn.weight', 'model.15.m.0.cv1.bn.bias', 'model.15.m.0.cv1.bn.running_mean', 'model.15.m.0.cv1.bn.running_var', 'model.15.m.0.cv1.bn.num_batches_tracked', 'model.15.m.0.cv2.conv.weight', 'model.15.m.0.cv2.bn.weight', 'model.15.m.0.cv2.bn.bias', 'model.15.m.0.cv2.bn.running_mean', 'model.15.m.0.cv2.bn.running_var', 'model.15.m.0.cv2.bn.num_batches_tracked', 'model.15.m.1.cv1.conv.weight', 'model.15.m.1.cv1.bn.weight', 'model.15.m.1.cv1.bn.bias', 'model.15.m.1.cv1.bn.running_mean', 'model.15.m.1.cv1.bn.running_var', 'model.15.m.1.cv1.bn.num_batches_tracked', 'model.15.m.1.cv2.conv.weight', 'model.15.m.1.cv2.bn.weight', 'model.15.m.1.cv2.bn.bias', 'model.15.m.1.cv2.bn.running_mean', 'model.15.m.1.cv2.bn.running_var', 'model.15.m.1.cv2.bn.num_batches_tracked', 'model.15.m.2.cv1.conv.weight', 'model.15.m.2.cv1.bn.weight', 'model.15.m.2.cv1.bn.bias', 'model.15.m.2.cv1.bn.running_mean', 'model.15.m.2.cv1.bn.running_var', 'model.15.m.2.cv1.bn.num_batches_tracked', 'model.15.m.2.cv2.conv.weight', 'model.15.m.2.cv2.bn.weight', 'model.15.m.2.cv2.bn.bias', 'model.15.m.2.cv2.bn.running_mean', 'model.15.m.2.cv2.bn.running_var', 'model.15.m.2.cv2.bn.num_batches_tracked', 'model.16.conv.weight', 'model.16.bn.weight', 'model.16.bn.bias', 'model.16.bn.running_mean', 'model.16.bn.running_var', 'model.16.bn.num_batches_tracked', 'model.18.cv1.conv.weight', 'model.18.cv1.bn.weight', 'model.18.cv1.bn.bias', 'model.18.cv1.bn.running_mean', 'model.18.cv1.bn.running_var', 'model.18.cv1.bn.num_batches_tracked', 'model.18.cv2.conv.weight', 'model.18.cv2.bn.weight', 'model.18.cv2.bn.bias', 'model.18.cv2.bn.running_mean', 'model.18.cv2.bn.running_var', 'model.18.cv2.bn.num_batches_tracked', 'model.18.m.0.cv1.conv.weight', 'model.18.m.0.cv1.bn.weight', 'model.18.m.0.cv1.bn.bias', 'model.18.m.0.cv1.bn.running_mean', 'model.18.m.0.cv1.bn.running_var', 'model.18.m.0.cv1.bn.num_batches_tracked', 'model.18.m.0.cv2.conv.weight', 'model.18.m.0.cv2.bn.weight', 'model.18.m.0.cv2.bn.bias', 'model.18.m.0.cv2.bn.running_mean', 'model.18.m.0.cv2.bn.running_var', 'model.18.m.0.cv2.bn.num_batches_tracked', 'model.18.m.1.cv1.conv.weight', 'model.18.m.1.cv1.bn.weight', 'model.18.m.1.cv1.bn.bias', 'model.18.m.1.cv1.bn.running_mean', 'model.18.m.1.cv1.bn.running_var', 'model.18.m.1.cv1.bn.num_batches_tracked', 'model.18.m.1.cv2.conv.weight', 'model.18.m.1.cv2.bn.weight', 'model.18.m.1.cv2.bn.bias', 'model.18.m.1.cv2.bn.running_mean', 'model.18.m.1.cv2.bn.running_var', 'model.18.m.1.cv2.bn.num_batches_tracked', 'model.18.m.2.cv1.conv.weight', 'model.18.m.2.cv1.bn.weight', 'model.18.m.2.cv1.bn.bias', 'model.18.m.2.cv1.bn.running_mean', 'model.18.m.2.cv1.bn.running_var', 'model.18.m.2.cv1.bn.num_batches_tracked', 'model.18.m.2.cv2.conv.weight', 'model.18.m.2.cv2.bn.weight', 'model.18.m.2.cv2.bn.bias', 'model.18.m.2.cv2.bn.running_mean', 'model.18.m.2.cv2.bn.running_var', 'model.18.m.2.cv2.bn.num_batches_tracked', 'model.19.conv.weight', 'model.19.bn.weight', 'model.19.bn.bias', 'model.19.bn.running_mean', 'model.19.bn.running_var', 'model.19.bn.num_batches_tracked', 'model.21.cv1.conv.weight', 'model.21.cv1.bn.weight', 'model.21.cv1.bn.bias', 'model.21.cv1.bn.running_mean', 'model.21.cv1.bn.running_var', 'model.21.cv1.bn.num_batches_tracked', 'model.21.cv2.conv.weight', 'model.21.cv2.bn.weight', 'model.21.cv2.bn.bias', 'model.21.cv2.bn.running_mean', 'model.21.cv2.bn.running_var', 'model.21.cv2.bn.num_batches_tracked', 'model.21.m.0.cv1.conv.weight', 'model.21.m.0.cv1.bn.weight', 'model.21.m.0.cv1.bn.bias', 'model.21.m.0.cv1.bn.running_mean', 'model.21.m.0.cv1.bn.running_var', 'model.21.m.0.cv1.bn.num_batches_tracked', 'model.21.m.0.cv2.conv.weight', 'model.21.m.0.cv2.bn.weight', 'model.21.m.0.cv2.bn.bias', 'model.21.m.0.cv2.bn.running_mean', 'model.21.m.0.cv2.bn.running_var', 'model.21.m.0.cv2.bn.num_batches_tracked', 'model.21.m.1.cv1.conv.weight', 'model.21.m.1.cv1.bn.weight', 'model.21.m.1.cv1.bn.bias', 'model.21.m.1.cv1.bn.running_mean', 'model.21.m.1.cv1.bn.running_var', 'model.21.m.1.cv1.bn.num_batches_tracked', 'model.21.m.1.cv2.conv.weight', 'model.21.m.1.cv2.bn.weight', 'model.21.m.1.cv2.bn.bias', 'model.21.m.1.cv2.bn.running_mean', 'model.21.m.1.cv2.bn.running_var', 'model.21.m.1.cv2.bn.num_batches_tracked', 'model.21.m.2.cv1.conv.weight', 'model.21.m.2.cv1.bn.weight', 'model.21.m.2.cv1.bn.bias', 'model.21.m.2.cv1.bn.running_mean', 'model.21.m.2.cv1.bn.running_var', 'model.21.m.2.cv1.bn.num_batches_tracked', 'model.21.m.2.cv2.conv.weight', 'model.21.m.2.cv2.bn.weight', 'model.21.m.2.cv2.bn.bias', 'model.21.m.2.cv2.bn.running_mean', 'model.21.m.2.cv2.bn.running_var', 'model.21.m.2.cv2.bn.num_batches_tracked', 'model.22.cv2.0.0.conv.weight', 'model.22.cv2.0.0.bn.weight', 'model.22.cv2.0.0.bn.bias', 'model.22.cv2.0.0.bn.running_mean', 'model.22.cv2.0.0.bn.running_var', 'model.22.cv2.0.0.bn.num_batches_tracked', 'model.22.cv2.0.1.conv.weight', 'model.22.cv2.0.1.bn.weight', 'model.22.cv2.0.1.bn.bias', 'model.22.cv2.0.1.bn.running_mean', 'model.22.cv2.0.1.bn.running_var', 'model.22.cv2.0.1.bn.num_batches_tracked', 'model.22.cv2.0.2.weight', 'model.22.cv2.0.2.bias', 'model.22.cv2.1.0.conv.weight', 'model.22.cv2.1.0.bn.weight', 'model.22.cv2.1.0.bn.bias', 'model.22.cv2.1.0.bn.running_mean', 'model.22.cv2.1.0.bn.running_var', 'model.22.cv2.1.0.bn.num_batches_tracked', 'model.22.cv2.1.1.conv.weight', 'model.22.cv2.1.1.bn.weight', 'model.22.cv2.1.1.bn.bias', 'model.22.cv2.1.1.bn.running_mean', 'model.22.cv2.1.1.bn.running_var', 'model.22.cv2.1.1.bn.num_batches_tracked', 'model.22.cv2.1.2.weight', 'model.22.cv2.1.2.bias', 'model.22.cv2.2.0.conv.weight', 'model.22.cv2.2.0.bn.weight', 'model.22.cv2.2.0.bn.bias', 'model.22.cv2.2.0.bn.running_mean', 'model.22.cv2.2.0.bn.running_var', 'model.22.cv2.2.0.bn.num_batches_tracked', 'model.22.cv2.2.1.conv.weight', 'model.22.cv2.2.1.bn.weight', 'model.22.cv2.2.1.bn.bias', 'model.22.cv2.2.1.bn.running_mean', 'model.22.cv2.2.1.bn.running_var', 'model.22.cv2.2.1.bn.num_batches_tracked', 'model.22.cv2.2.2.weight', 'model.22.cv2.2.2.bias', 'model.22.cv3.0.0.conv.weight', 'model.22.cv3.0.0.bn.weight', 'model.22.cv3.0.0.bn.bias', 'model.22.cv3.0.0.bn.running_mean', 'model.22.cv3.0.0.bn.running_var', 'model.22.cv3.0.0.bn.num_batches_tracked', 'model.22.cv3.0.1.conv.weight', 'model.22.cv3.0.1.bn.weight', 'model.22.cv3.0.1.bn.bias', 'model.22.cv3.0.1.bn.running_mean', 'model.22.cv3.0.1.bn.running_var', 'model.22.cv3.0.1.bn.num_batches_tracked', 'model.22.cv3.0.2.weight', 'model.22.cv3.0.2.bias', 'model.22.cv3.1.0.conv.weight', 'model.22.cv3.1.0.bn.weight', 'model.22.cv3.1.0.bn.bias', 'model.22.cv3.1.0.bn.running_mean', 'model.22.cv3.1.0.bn.running_var', 'model.22.cv3.1.0.bn.num_batches_tracked', 'model.22.cv3.1.1.conv.weight', 'model.22.cv3.1.1.bn.weight', 'model.22.cv3.1.1.bn.bias', 'model.22.cv3.1.1.bn.running_mean', 'model.22.cv3.1.1.bn.running_var', 'model.22.cv3.1.1.bn.num_batches_tracked', 'model.22.cv3.1.2.weight', 'model.22.cv3.1.2.bias', 'model.22.cv3.2.0.conv.weight', 'model.22.cv3.2.0.bn.weight', 'model.22.cv3.2.0.bn.bias', 'model.22.cv3.2.0.bn.running_mean', 'model.22.cv3.2.0.bn.running_var', 'model.22.cv3.2.0.bn.num_batches_tracked', 'model.22.cv3.2.1.conv.weight', 'model.22.cv3.2.1.bn.weight', 'model.22.cv3.2.1.bn.bias', 'model.22.cv3.2.1.bn.running_mean', 'model.22.cv3.2.1.bn.running_var', 'model.22.cv3.2.1.bn.num_batches_tracked', 'model.22.cv3.2.2.weight', 'model.22.cv3.2.2.bias', 'model.22.dfl.conv.weight', 'model.22.cv4.0.0.conv.weight', 'model.22.cv4.0.0.bn.weight', 'model.22.cv4.0.0.bn.bias', 'model.22.cv4.0.0.bn.running_mean', 'model.22.cv4.0.0.bn.running_var', 'model.22.cv4.0.0.bn.num_batches_tracked', 'model.22.cv4.0.1.conv.weight', 'model.22.cv4.0.1.bn.weight', 'model.22.cv4.0.1.bn.bias', 'model.22.cv4.0.1.bn.running_mean', 'model.22.cv4.0.1.bn.running_var', 'model.22.cv4.0.1.bn.num_batches_tracked', 'model.22.cv4.0.2.weight', 'model.22.cv4.0.2.bias', 'model.22.cv4.1.0.conv.weight', 'model.22.cv4.1.0.bn.weight', 'model.22.cv4.1.0.bn.bias', 'model.22.cv4.1.0.bn.running_mean', 'model.22.cv4.1.0.bn.running_var', 'model.22.cv4.1.0.bn.num_batches_tracked', 'model.22.cv4.1.1.conv.weight', 'model.22.cv4.1.1.bn.weight', 'model.22.cv4.1.1.bn.bias', 'model.22.cv4.1.1.bn.running_mean', 'model.22.cv4.1.1.bn.running_var', 'model.22.cv4.1.1.bn.num_batches_tracked', 'model.22.cv4.1.2.weight', 'model.22.cv4.1.2.bias', 'model.22.cv4.2.0.conv.weight', 'model.22.cv4.2.0.bn.weight', 'model.22.cv4.2.0.bn.bias', 'model.22.cv4.2.0.bn.running_mean', 'model.22.cv4.2.0.bn.running_var', 'model.22.cv4.2.0.bn.num_batches_tracked', 'model.22.cv4.2.1.conv.weight', 'model.22.cv4.2.1.bn.weight', 'model.22.cv4.2.1.bn.bias', 'model.22.cv4.2.1.bn.running_mean', 'model.22.cv4.2.1.bn.running_var', 'model.22.cv4.2.1.bn.num_batches_tracked', 'model.22.cv4.2.2.weight', 'model.22.cv4.2.2.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_clip_augmented', '_compiled_call_impl', '_descale_pred', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_predict_augment', '_predict_once', '_profile_one_layer', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'args', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'fuse', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'info', 'init_criterion', 'inplace', 'ipu', 'is_fused', 'kpt_shape', 'load', 'load_state_dict', 'loss', 'model', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'names', 'nc', 'parameters', 'predict', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'save', 'set_extra_state', 'share_memory', 'state_dict', 'stride', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'yaml', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-2): 3 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-5): 6 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-5): 6 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-2): 3 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-2): 3 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-2): 3 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-2): 3 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-2): 3 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Pose(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (cv4): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(80, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(80, 51, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.YOLO.yolo import YOLO, get_yolo_model, get_keypoints_yolo, YoloKeypointLoss\n",
    "import torch\n",
    "import cv2\n",
    "from utils import load_config\n",
    "from dataset import PoseDataset\n",
    "\n",
    "model = get_yolo_model('yolov8x-pose', 17)\n",
    "\n",
    "\n",
    "config = load_config('./configs/config_YOLO_x.yaml')\n",
    "\n",
    "n = 1\n",
    "dataset = PoseDataset(config[\"dataset\"], config[\"dataset\"]['val'])\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=n, shuffle=True)\n",
    "images,targets,keypoints_gts,keypoint_visibilitys = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51, 8400])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = model(images)\n",
    "print(out.shape)\n",
    "keypoints = get_keypoints_yolo(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 17, 8400])\n"
     ]
    }
   ],
   "source": [
    "loss = YoloKeypointLoss()\n",
    "loss(out, targets, keypoints_gts, keypoint_visibilitys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show = images[0].permute(1, 2, 0).numpy()\n",
    "image_show = cv2.resize(image_show, config['dataset']['preprocess']['input_size'])\n",
    "image_show = cv2.cvtColor(image_show, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "for i in range(keypoints.shape[1]):\n",
    "    x = keypoints[0, i, 0].item()\n",
    "    y = keypoints[0, i, 1].item()\n",
    "    conf = keypoints[0, i, 2].item()\n",
    "    if conf > 0.5:\n",
    "        cv2.circle(image_show, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "cv2.imshow('keypoints', image_show)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
